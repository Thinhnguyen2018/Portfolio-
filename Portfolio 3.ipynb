{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2847cd9-68b2-4f1c-878a-dbe250cb95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the CSV path\n",
    "csv_path = r'C:\\Users\\ADMIN\\Downloads\\ampc2\\\\'\n",
    "\n",
    "# Load the CSV files\n",
    "df1 = pd.read_csv(csv_path + 'Boning.csv')\n",
    "df2 = pd.read_csv(csv_path + 'Slicing.csv')\n",
    "\n",
    "# Select relevant columns from each DataFrame\n",
    "df1_selected = df1[['Frame', 'Right Hand x', 'Right Hand y', 'Right Hand z']].copy()\n",
    "df2_selected = df2[['Frame', 'Left Hand x', 'Left Hand y', 'Left Hand z']].copy()\n",
    "\n",
    "# Add class column to each selected DataFrame\n",
    "df1_selected['class'] = 0  # Boning\n",
    "df2_selected['class'] = 1  # Slicing\n",
    "\n",
    "# Rename columns to have a common structure, excluding the separate class column\n",
    "df1_selected.columns = ['Frame', 'Right Hand x', 'Right Hand y', 'Right Hand z', 'class']\n",
    "df2_selected.columns = ['Frame', 'Left Hand x', 'Left Hand y', 'Left Hand z', 'class']\n",
    "\n",
    "combined_df =pd.concat([df1_selected,df2_selected], ignore_index=True)\n",
    "\n",
    "#Move class columns to the end\n",
    "cols = combined_df.columns.tolist()\n",
    "cols.append(cols.pop(cols.index('class'))) \n",
    "combined_df = combined_df[cols]\n",
    "\n",
    "#Save the data collection into a new csv\n",
    "combined_df.to_csv('portfolio3.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d8fc38-7667-43bc-94d3-52f8f2cd95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "combined_df['Right Hand RMS x,y'] = np.sqrt((combined_df['Right Hand x']**2) + (combined_df['Right Hand y']**2) )\n",
    "combined_df['Right Hand RMS y,z'] = np.sqrt((combined_df['Right Hand y']**2) + (combined_df['Right Hand z']**2) )\n",
    "combined_df['Right Hand RMS z,x'] = np.sqrt((combined_df['Right Hand z']**2) + (combined_df['Right Hand x']**2) )\n",
    "combined_df['Right Hand RMS x,y,z'] = np.sqrt((combined_df['Right Hand x']**2) + (combined_df['Right Hand y']**2) + (combined_df['Right Hand z']**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12157c9-2afa-46f6-ac77-d030f68bac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Right Hand Roll'] = 180 * np.arctan2(combined_df['Right Hand y'], np.sqrt(combined_df['Right Hand x']**2 + combined_df['Right Hand z']**2)) / np.pi\n",
    "combined_df['Right Hand Pitch'] = 180 * np.arctan2(combined_df['Right Hand x'], np.sqrt(combined_df['Right Hand y']**2 + combined_df['Right Hand z']**2)) / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6199fc-0728-489e-971d-2d4b769ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Left Hand RMS x,y'] = np.sqrt((combined_df['Left Hand x']**2) + (combined_df['Left Hand y']**2) )\n",
    "combined_df['Left Hand RMS y,z'] = np.sqrt((combined_df['Left Hand y']**2) + (combined_df['Left Hand z']**2) )\n",
    "combined_df['Left Hand RMS z,x'] = np.sqrt((combined_df['Left Hand z']**2) + (combined_df['Left Hand x']**2) )\n",
    "combined_df['Left Hand RMS x,y,z'] = np.sqrt((combined_df['Left Hand x']**2) + (combined_df['Left Hand y']**2) + (combined_df['Left Hand z']**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad066d90-df93-4348-9390-fa7fe56a183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Left Hand Roll'] = 180 * np.arctan2(combined_df['Left Hand y'], np.sqrt(combined_df['Left Hand x']**2 + combined_df['Left Hand z']**2)) / np.pi\n",
    "combined_df['Left Hand Pitch'] = 180 * np.arctan2(combined_df['Left Hand x'], np.sqrt(combined_df['Left Hand y']**2 + combined_df['Left Hand z']**2)) / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6407161-858b-4086-853d-4dae0241ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = combined_df.columns.tolist()\n",
    "cols.append(cols.pop(cols.index('class'))) \n",
    "combined_df = combined_df[cols]\n",
    "\n",
    "combined_df.to_csv('portfolio3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbe119f-ac89-479e-8a75-9927941a1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import simpson\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e9e435-e68a-4449-8919-ec9ea9880a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Minute'] = combined_df.index //60\n",
    "feature_list = []\n",
    "columns_to_compute = combined_df.columns[1:19]\n",
    "for column in columns_to_compute:\n",
    "    grouped = combined_df.groupby('Minute')[column]\n",
    "    means = grouped.mean()\n",
    "    stds = grouped.std()\n",
    "    mins = grouped.min()\n",
    "    maxs = grouped.max()\n",
    "    aucs = grouped.apply(lambda x: simpson(x, dx=1) if len(x) > 1 else 0)\n",
    "    peaks_counts = grouped.apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    feature_df = pd.DataFrame({\n",
    "            'Mean': means,\n",
    "            'Std': stds,\n",
    "            'Min': mins,\n",
    "            'Max': maxs,\n",
    "            'AUC': aucs,\n",
    "            'Peaks': peaks_counts\n",
    "        })\n",
    "\n",
    "\n",
    "    feature_df.columns = [f\"{column}_{feature}\" for feature in feature_df.columns]  # Rename columns\n",
    "    feature_list.append(feature_df)\n",
    "\n",
    "final_features = pd.concat(feature_list, axis=1)\n",
    "\n",
    "class_column = combined_df.groupby('Minute')['class'].first()\n",
    "\n",
    "final_features['class'] = class_column.values\n",
    "\n",
    "final_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final_features.to_csv('portfolio3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f38af665-4f0b-4c9f-89a6-0a74db0c0c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train-Test split (70/30)</td>\n",
       "      <td>0.746276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Scenario  Accuracy\n",
       "0  Train-Test split (70/30)  0.746276"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the features (X) and the target variable (y)\n",
    "data=pd.read_csv('portfolio3.csv')\n",
    "\n",
    "X = data.drop('class', axis=1)  # Features\n",
    "y = data['class']  # Target variable (class)\n",
    "\n",
    "# Fill any missing values in X with the mean of the respective columns\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "results = {\n",
    "    'Scenario': [],\n",
    "    'Accuracy': []\n",
    "}\n",
    "\n",
    "# Train an SVM model\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_split = accuracy_score(y_test, y_pred)\n",
    "results['Scenario'].append('Train-Test split (70/30)')\n",
    "results['Accuracy'].append(accuracy_split)\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a652378-643e-404d-9de2-c009a0b4f01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'C': 0.1, 'gamma': 1, 'kernel': 'linear'}, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a parameter grid to tune the SVM model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    'kernel': ['rbf', 'linear']  # Kernel type to be used in the algorithm\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object to search for the best parameters\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, refit=True, verbose=1)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Predict using the best model found\n",
    "y_pred_best = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the tuned model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "best_params, accuracy_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f837d5aa-a8a2-4e8e-9972-4c62776fae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "results = {\n",
    "    'Scenario': [],\n",
    "    'Accuracy': []\n",
    "}\n",
    "\n",
    "cv_scores = cross_val_score(clf, X, y, cv=10)\n",
    "cv_accuracy = cv_scores.mean()\n",
    "results['Scenario'].append('10-fold cross-validation (default)')\n",
    "results['Accuracy'].append(cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07f5d6ea-c332-4b11-aded-cfbea78f3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 features\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Train-test split\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y, test_size=0.3, random_state=1)\n",
    "clf_new = svm.SVC(C=0.1, gamma=1, kernel='linear')\n",
    "clf_new.fit(X_train_new, y_train_new)\n",
    "y_pred_new = clf_new.predict(X_test_new)\n",
    "accuracy_split_tuned_feat = accuracy_score(y_test_new, y_pred_new)\n",
    "results['Scenario'].append('Train-Test split with tuning and top 10 features')\n",
    "results['Accuracy'].append(accuracy_split_tuned_feat)\n",
    "\n",
    "# 10-fold cross-validation\n",
    "cv_scores_tuned_feat = cross_val_score(clf_new, X_new, y, cv=10)\n",
    "cv_accuracy_tuned_feat = cv_scores_tuned_feat.mean()\n",
    "results['Scenario'].append('10-fold cross-validation with tuning and top 10 features')\n",
    "results['Accuracy'].append(cv_accuracy_tuned_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14830a10-6fed-4a6d-a838-95ce47eaabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to get the top 10 principal components\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=1)\n",
    "clf_pca = svm.SVC(C=0.1, gamma=1, kernel='linear')\n",
    "clf_pca.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = clf_pca.predict(X_test_pca)\n",
    "accuracy_split_tuned_pca = accuracy_score(y_test_pca, y_pred_pca)\n",
    "results['Scenario'].append('Train-Test split with tuning and top 10 principal components')\n",
    "results['Accuracy'].append(accuracy_split_tuned_pca)\n",
    "\n",
    "# 10-fold cross-validation\n",
    "cv_scores_tuned_pca = cross_val_score(clf_pca, X_pca, y, cv=10)\n",
    "cv_accuracy_tuned_pca = cv_scores_tuned_pca.mean()\n",
    "results['Scenario'].append('10-fold cross-validation with tuning and top 10 principal components')\n",
    "results['Accuracy'].append(cv_accuracy_tuned_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176a4792-1493-4005-beb0-fec0e623f0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-fold cross-validation (default)</td>\n",
       "      <td>0.985854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train-Test split with tuning and top 10 features</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-fold cross-validation with tuning and top 1...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train-Test split with tuning and top 10 princi...</td>\n",
       "      <td>0.797784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-fold cross-validation with tuning and top 1...</td>\n",
       "      <td>0.765999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Scenario  Accuracy\n",
       "0                 10-fold cross-validation (default)  0.985854\n",
       "1   Train-Test split with tuning and top 10 features  1.000000\n",
       "2  10-fold cross-validation with tuning and top 1...  1.000000\n",
       "3  Train-Test split with tuning and top 10 princi...  0.797784\n",
       "4  10-fold cross-validation with tuning and top 1...  0.765999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba6373-9cf2-4afb-b50c-d7a8708d3c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7b6ab-3a12-4814-b6ee-8406cc42c452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
